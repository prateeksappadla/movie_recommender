{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement the Collaborative Filtering Techniques for the smaller version of the dataset. The ratings matrices are represented using numpy ndarrays. This is a simple implementation, which does not scale to the larger dataset. Recall that the ratings matrix is sparse and we can make use of the sparse nature to make the code more efficient.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 671\n",
      "Number of unique movies: 9066\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "filename = '../../data/ml-latest-small/ratings.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "n_users = df['userId'].unique().shape[0]\n",
    "n_items = df['movieId'].unique().shape[0]\n",
    "print(\"Number of unique users: %d\" % n_users)\n",
    "print(\"Number of unique movies: %d\" % n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from movieId to index\n",
    "ind = 0\n",
    "movie_dict = {}\n",
    "movie_list = []\n",
    "\n",
    "for item in df['movieId'].unique():\n",
    "    movie_list.append(item)\n",
    "    movie_dict[item] = ind\n",
    "    ind += 1   \n",
    "    \n",
    "assert(len(movie_list) == n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create user-item ratings matrix from the csv file data\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "\n",
    "# df.itertuples() returns a Pandas Frame object\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1] - 1, movie_dict[row[2]]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets by removing 10 ratings per user from the training set and adding to test set \n",
    "# All selected users had rated at least 20 movies. There are a total of 100004 ratings in this version of the dataset\n",
    "# 10 ratings per user means a test set comprising of 6710 ratings which is around 6.7% of the total data\n",
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to compute the mean squared error between the predictions and the test data\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore zero terms in the matrix\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average rating: 3.53507192317\n",
      "Global Average Baseline MSE: 1.16011429484\n"
     ]
    }
   ],
   "source": [
    "def global_average_baseline(ratings):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    global_avg = np.sum(ratings) / np.count_nonzero(ratings)\n",
    "    pred += global_avg\n",
    "    return pred\n",
    "\n",
    "global_avg_predictions = global_average_baseline(train)\n",
    "print(\"Global average rating: \" + str(global_avg_predictions[0,0]))\n",
    "global_avg_mse = get_mse(global_avg_predictions, test)\n",
    "print(\"Global Average Baseline MSE: \" + str(global_avg_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5         2.5         2.5         2.5         2.5       ]\n",
      " [ 3.46969697  3.46969697  3.46969697  3.46969697  3.46969697]\n",
      " [ 3.53658537  3.53658537  3.53658537  3.53658537  3.53658537]\n",
      " [ 4.37628866  4.37628866  4.37628866  4.37628866  4.37628866]\n",
      " [ 3.91111111  3.91111111  3.91111111  3.91111111  3.91111111]]\n",
      "User Average MSE: 0.9653437804\n"
     ]
    }
   ],
   "source": [
    "def user_average(ratings):\n",
    "    # Small constant used for numerical stability\n",
    "    epsilon = 1e-9\n",
    "    user_avg = np.sum(ratings,axis=1) / (np.count_nonzero(ratings,axis=1) + epsilon)\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    pred += np.expand_dims(user_avg,axis=1)\n",
    "    return pred\n",
    "\n",
    "user_avg_predictions = user_average(train)\n",
    "print(user_avg_predictions[:5, :5])\n",
    "user_avg_mse = get_mse(user_avg_predictions, test)\n",
    "print(\"User Average MSE: \" + str(user_avg_mse))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.22222222  3.68421053  3.58064516  3.32608696  4.26744186]\n",
      " [ 3.22222222  3.68421053  3.58064516  3.32608696  4.26744186]\n",
      " [ 3.22222222  3.68421053  3.58064516  3.32608696  4.26744186]\n",
      " [ 3.22222222  3.68421053  3.58064516  3.32608696  4.26744186]\n",
      " [ 3.22222222  3.68421053  3.58064516  3.32608696  4.26744186]]\n",
      "Movie Average MSE: 1.20952099045\n"
     ]
    }
   ],
   "source": [
    "def movie_average(ratings):\n",
    "    epsilon = 1e-9\n",
    "    movie_avg = np.sum(ratings,axis=0) / (np.count_nonzero(ratings, axis=0) + epsilon)\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    pred += np.expand_dims(movie_avg,axis=0)\n",
    "    return pred\n",
    "\n",
    "movie_avg_predictions = movie_average(train)\n",
    "print(movie_avg_predictions[:5,:5])\n",
    "movie_avg_mse = get_mse(movie_avg_predictions,test)\n",
    "print(\"Movie Average MSE: \" + str(movie_avg_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.1871503   2.6491386   2.54557324  2.29101503  3.23236994]\n",
      " [ 3.15684727  3.61883557  3.51527021  3.260712    4.20206691]\n",
      " [ 3.22373566  3.68572397  3.5821586   3.3276004   4.2689553 ]\n",
      " [ 4.06343896  4.52542726  4.4218619   4.16730369  5.1086586 ]\n",
      " [ 3.59826141  4.06024971  3.95668435  3.70212614  4.64348105]]\n",
      "Global Baseline Method MSE: 1.09267332671\n"
     ]
    }
   ],
   "source": [
    "# Global Baseline method\n",
    "def global_baseline_method(ratings):\n",
    "    \"\"\"Global Baseline Method\n",
    "        r_ij = b + u_ib + m_jb \n",
    "        r_ij: predicted rating for a user i for movie j\n",
    "        b: global average rating\n",
    "        u_ib: difference of avergae rating given by user and the global average (Captures bias of user)\n",
    "        m_jb: difference of average rating given to movie and the global average    \n",
    "    \"\"\"\n",
    "    epsilon=1e-9\n",
    "    global_avg = np.sum(ratings) / np.count_nonzero(ratings) \n",
    "    \n",
    "    user_avg = np.sum(ratings,axis=1) / (np.count_nonzero(ratings, axis=1) + epsilon)\n",
    "    user_bias = user_avg - global_avg\n",
    "    \n",
    "    movie_avg = np.sum(ratings, axis=0) / (np.count_nonzero(ratings,axis=0) + epsilon)\n",
    "    movie_bias = movie_avg - global_avg\n",
    "    \n",
    "    pred = np.zeros(ratings.shape)\n",
    "    pred += global_avg\n",
    "    pred += np.expand_dims(user_bias,axis=1)\n",
    "    pred += np.expand_dims(movie_bias,axis=0)\n",
    "    return pred\n",
    "\n",
    "gbm_predictions = global_baseline_method(train)\n",
    "print(gbm_predictions[:5,:5])\n",
    "gbm_mse = get_mse(gbm_predictions, test)\n",
    "print(\"Global Baseline Method MSE: \" + str(gbm_mse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User CF MSE: 1.31555866391\n"
     ]
    }
   ],
   "source": [
    "# User - User Collaborative Filtering\n",
    "\n",
    "def user_centered_cosine(ratings):\n",
    "    \"\"\"Method to compute user-user similarity matrix using centered cosine similarity\n",
    "    \"\"\"   \n",
    "    epsilon=1e-9\n",
    "    centered_ratings = np.zeros(ratings.shape)\n",
    "    non_zero = (ratings != 0).astype(int)\n",
    "    \n",
    "    user_avg = np.sum(ratings,axis=1) / (np.count_nonzero(ratings, axis=1) + epsilon)\n",
    "    # Subtract average user rating from each rating\n",
    "    centered_ratings = ratings - np.expand_dims(user_avg,axis=1)\n",
    "    centered_ratings *= non_zero\n",
    "    sim = centered_ratings.dot(centered_ratings.T)\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "def user_cf_predictions(ratings, user_similarity, k=20):\n",
    "    \"\"\"Method to make user-user CF predictions\n",
    "        k: Number of similar users to use to make predictions\n",
    "    \"\"\"\n",
    "    epsilon=1e-9\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    #Select top k similar users for each user\n",
    "    top_k = np.argsort(user_similarity,axis=1)[:,-k-1:-1]\n",
    "    \n",
    "    for user in range(ratings.shape[0]):\n",
    "        top_k_sim = user_similarity[user,top_k[user]]\n",
    "        pred[user] = np.expand_dims(top_k_sim,axis=0).dot(ratings[top_k[user],:])\n",
    "        \n",
    "        # Normalize predictions by dividing by sum of similarities corresponding to similar users who have non-zero ratings\n",
    "        # for this movie\n",
    "        non_zero_ratings = (ratings[top_k[user],:] != 0).astype(int)\n",
    "        normalizer = np.sum(np.expand_dims(top_k_sim,axis=1) * non_zero_ratings, axis=0)\n",
    "        pred[user] /= (normalizer + epsilon) \n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "user_sim = user_centered_cosine(train)\n",
    "user_cf_predictions = user_cf_predictions(train, user_sim, 200)\n",
    "user_cf_mse = get_mse(user_cf_predictions, test)\n",
    "print(\"User-User CF MSE: \"+ str(user_cf_mse))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 200)\n",
      "Bias Adjusted User-User CF MSE: 0.885999870192\n"
     ]
    }
   ],
   "source": [
    "def user_cf_predictions_bias(ratings, user_similarity, k=20):\n",
    "    \"\"\"Method to make user-user CF predictions by adjusting for user bias\n",
    "        k: Number of similar users to use to make predictions\n",
    "    \"\"\"\n",
    "    epsilon=1e-9\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    centered_ratings = np.zeros(ratings.shape)\n",
    "    non_zero = (ratings != 0).astype(int)\n",
    "    \n",
    "    user_avg = np.sum(ratings,axis=1) / (np.count_nonzero(ratings, axis=1) + epsilon)\n",
    "    pred += np.expand_dims(user_avg, axis=1)\n",
    "    # Subtract average user rating from each rating\n",
    "    centered_ratings = ratings - np.expand_dims(user_avg,axis=1)\n",
    "    centered_ratings *= non_zero\n",
    "\n",
    "    # Select top k similar users for each user (Shape of top_k = (num_users,k))\n",
    "    top_k = np.argsort(user_similarity,axis=1)[:,-k-1:-1]\n",
    "    print(top_k.shape)\n",
    "    \n",
    "    for user in range(ratings.shape[0]):\n",
    "        top_k_sim = user_similarity[user,top_k[user]]\n",
    "        \n",
    "        # Normalize predictions by dividing by sum of similarities corresponding to similar users who have non-zero ratings\n",
    "        # for this movie\n",
    "        non_zero_ratings = (centered_ratings[top_k[user],:] != 0).astype(int)\n",
    "        normalizer = np.sum(np.expand_dims(top_k_sim,axis=1) * non_zero_ratings, axis=0)\n",
    "            \n",
    "        pred[user] += (np.expand_dims(top_k_sim,axis=0).dot(centered_ratings[top_k[user],:]) / (np.expand_dims(normalizer,axis=0) + epsilon)).flatten()\n",
    "    \n",
    "    return pred\n",
    "\n",
    "bias_user_cf_predictions = user_cf_predictions_bias(train, user_sim, 200)\n",
    "bias_user_cf_mse = get_mse(bias_user_cf_predictions, test)\n",
    "print(\"Bias Adjusted User-User CF MSE: \"+ str(bias_user_cf_mse))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Item_Item Collaborative Filtering\n",
    "\n",
    "def item_centered_cosine(ratings):\n",
    "    epsilon=1e-9\n",
    "    centered_ratings = np.zeros(ratings.shape)\n",
    "    \n",
    "    item_avg = np.sum(ratings,axis=0,dtype=np.float64) / (np.count_nonzero(ratings, axis=0) + epsilon)\n",
    "    non_zero = (ratings != 0).astype(int)\n",
    "    centered_ratings = ratings - item_avg.T\n",
    "    centered_ratings *= non_zero\n",
    "    \n",
    "    sim = centered_ratings.T.dot(centered_ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "item_sim = item_centered_cosine(train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9066, 1000)\n",
      "Bias Adjusted Item-Item CF MSE: 1.06680154999\n"
     ]
    }
   ],
   "source": [
    "def item_cf_predictions_bias(ratings, item_sim, k=20):\n",
    "    \"\"\"Method to make item-item CF predictions by adjusting for user bias\n",
    "        k: Number of similar users to use to make predictions\n",
    "    \"\"\"\n",
    "    epsilon=1e-9\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    non_zero = (ratings != 0).astype(int)\n",
    "        \n",
    "    centered_ratings = np.zeros(ratings.shape)\n",
    "\n",
    "    movie_avg = np.sum(ratings,axis=0) / (np.count_nonzero(ratings, axis=0) + epsilon)\n",
    "    pred += np.expand_dims(movie_avg, axis=0)\n",
    "    \n",
    "    centered_ratings = ratings - np.expand_dims(movie_avg,axis=0)\n",
    "    centered_ratings *= non_zero\n",
    "    \n",
    "    \n",
    "    # Select top-k similar items for each item\n",
    "    top_k = np.argsort(item_sim,axis=1)[:,-k-1:-1]\n",
    "    print(top_k.shape)\n",
    "    \n",
    "    \n",
    "    for movie in range(ratings.shape[1]):\n",
    "        top_k_sim = item_sim[movie,top_k[movie]]\n",
    "        #print(top_k_sim.shape)\n",
    "        \n",
    "        non_zero_ratings = (centered_ratings[:,top_k[movie]] != 0).astype(int)\n",
    "        #print(non_zero_ratings.shape)\n",
    "        normalizer = np.sum(np.expand_dims(top_k_sim,axis=0) * non_zero_ratings, axis=1)\n",
    "        #print(normalizer.shape)\n",
    "        \n",
    "        #print((centered_ratings[:,top_k[movie]].dot(top_k_sim) / (normalizer + epsilon)).shape)\n",
    "        pred[:,movie] += (centered_ratings[:,top_k[movie]].dot(top_k_sim) / (normalizer + epsilon))\n",
    "    return pred     \n",
    "\n",
    "\n",
    "bias_item_cf_predictions = item_cf_predictions_bias(train, item_sim, 1000)\n",
    "bias_item_cf_mse = get_mse(bias_item_cf_predictions, test)\n",
    "print(\"Bias Adjusted Item-Item CF MSE: \"+ str(bias_item_cf_mse))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 671) (671,) (9066, 9066)\n"
     ]
    }
   ],
   "source": [
    "# Latent Factor Model\n",
    "\n",
    "# Two possibilities: 1. Initialize P and Q using SVD, then learn using SGD\n",
    "# 2. Choose k(number of latent factors as a hyperparameter, initialize P and Q randomly and then learn using SGD) \n",
    "from numpy.linalg import svd\n",
    "\n",
    "Q , s, P = svd(train,full_matrices=True)\n",
    "print(Q.shape, s.shape, P.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 498.74674409  235.65329323  191.42905068  155.10213499  145.96675649\n",
      "  140.63605568  131.6124867   119.55262734  114.72282105  113.25528472\n",
      "  107.98422453  104.24389205   99.7284695    93.9742545    91.73155926\n",
      "   91.41034686   90.13768744   88.82310863   87.39525466   87.08776017\n",
      "   84.58013003   83.61941032   81.92961216   81.160108     80.71991308\n",
      "   79.81193979   78.72740293   77.47124266   77.20518683   76.47606082]\n",
      "[ 6.19488374  6.13341563  6.08468363  5.92029403  5.91229635  5.85113899\n",
      "  5.82242547  5.71201519  5.65378349  5.53003035  5.46031087  5.42204386\n",
      "  5.37049866  5.35200619  5.13425571  5.087025    4.98207196  4.94991828\n",
      "  4.91761016  4.748509    4.62499337  4.45737976  4.31705614  4.18442336\n",
      "  4.08012303  3.82984693  3.57018429  3.25795395  3.03750485  2.7705835 ]\n"
     ]
    }
   ],
   "source": [
    "print(s[:30])\n",
    "print(s[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Latent Factor Model\n",
    "\n",
    "def learn_latent_factor_random(ratings, k=50, lambda1=1, lambda2=1, epochs=50, lr=0.1):\n",
    "    \"\"\"Learn a latent factor model for the ratings matrix\n",
    "        Randomly initialize Q and P matrices of dimensions\n",
    "        Q: n_users * k\n",
    "        P: n_items * k\n",
    "        \n",
    "        lambda1: regularization strength for Q\n",
    "        lambda2: regularization strength for P\n",
    "        and then learn by SGD\n",
    "    \"\"\"\n",
    "    \n",
    "#     Q = np.random.randn(ratings.shape[0], k)\n",
    "#     P = np.random.randn(ratings.shape[1], k)\n",
    "\n",
    "    Q = np.random.uniform(0,0.1,size=(ratings.shape[0], k))\n",
    "    P = np.random.uniform(0,0.1,size=(ratings.shape[1], k))\n",
    "    \n",
    "    non_zero_r = np.transpose(np.nonzero(ratings))\n",
    "    print(non_zero_r[0])\n",
    "    \n",
    "    for ep in range(1,epochs+1):\n",
    "        print(\"Epoch: \" + str(ep))\n",
    "        for rating in non_zero_r:\n",
    "            err = ratings[rating[0],rating[1]] - Q[rating[0],:].dot(P[rating[1],:])\n",
    "            #print(err)\n",
    "            grad_Q = 2 * (lambda2 * Q[rating[0],:] - (err)*P[rating[1],:])  \n",
    "            grad_P = 2 * (lambda1 * P[rating[1],:] - (err)*Q[rating[0],:])\n",
    "            \n",
    "            Q[rating[0],:] -= lr * grad_Q\n",
    "            P[rating[1],:] -= lr * grad_P                                           \n",
    "                                                       \n",
    "    return Q,P                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Epoch: 30\n",
      "Epoch: 31\n",
      "Epoch: 32\n",
      "Epoch: 33\n",
      "Epoch: 34\n",
      "Epoch: 35\n",
      "Epoch: 36\n",
      "Epoch: 37\n",
      "Epoch: 38\n",
      "Epoch: 39\n",
      "Epoch: 40\n",
      "Epoch: 41\n",
      "Epoch: 42\n",
      "Epoch: 43\n",
      "Epoch: 44\n",
      "Epoch: 45\n",
      "Epoch: 46\n",
      "Epoch: 47\n",
      "Epoch: 48\n",
      "Epoch: 49\n",
      "Epoch: 50\n",
      "Latent Factor Predictions MSE: 2.01439599943\n"
     ]
    }
   ],
   "source": [
    "#Q,P = learn_latent_factor_svd(train,650)\n",
    "Q,P = learn_latent_factor_random(train,500)\n",
    "\n",
    "def latent_factor_predictions(Q, P):\n",
    "    pred = Q.dot(P.T)\n",
    "    return pred\n",
    "\n",
    "lf_predictions = latent_factor_predictions(Q,P)\n",
    "lf_mse = get_mse(lf_predictions,test)\n",
    "print(\"Latent Factor Predictions MSE: \" + str(lf_mse))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
