{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 138493\n",
      "Number of unique movies: 26744\n"
     ]
    }
   ],
   "source": [
    "# Read the ratings csv file into a pandas Dataframe\n",
    "filename = '../../data/ml-20m/ratings.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "n_users = df['userId'].unique().shape[0]\n",
    "n_items = df['movieId'].unique().shape[0]\n",
    "print(\"Number of unique users: %d\" % n_users)\n",
    "print(\"Number of unique movies: %d\" % n_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \"\"\" Split the data into training, validation and test partitions by random sampling.\n",
    "\n",
    "        80% of the data is randomly sampled to be the training partition.\n",
    "        10% is held out as a validation dataset to tune the hyperparameters.\n",
    "        10% is held out as a test partition to test the final performance of the model.\n",
    "\n",
    "        Args\n",
    "            df: pandas dataframe object containing the dataset\n",
    "\n",
    "        Returns\n",
    "            df_train: Dataframe corresponding to training partition\n",
    "            df_valid: Dataframe corresponding to validation partition\n",
    "            df_test: Dataframe corresponding to test partition\n",
    "    \"\"\"\n",
    "    df_train = df.sample(frac=0.8)\n",
    "    df_rem = df.loc[~df.index.isin(df_train.index)]\n",
    "    df_valid = df_rem.sample(frac=0.5)\n",
    "    df_test = df_rem.loc[~df_rem.index.isin(df_valid.index)]\n",
    "#     logger.info(\"Shape of training dataframe: \" + str(df_train.shape))\n",
    "#     logger.info(\"Shape of validation dataframe: \" + str(df_valid.shape))\n",
    "#     logger.info(\"Sahpe of test dataframe: \" + str(df_test.shape))\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "\n",
    "def create_sparse_coo_matrix(df, n_users, n_items, movie_dict):\n",
    "    \"\"\" Create a scipy sparse coo matrix from the given dataframe \n",
    "\n",
    "        Args\n",
    "            df: Dataframe object to be converted to sparse matrix\n",
    "            n_users: Number of rows in the sparse matrix\n",
    "            n_items: Number of columns in the sparse matrix\n",
    "            movie_dict: Dictionary mapping the movies in the dataset to a movie id\n",
    "\n",
    "        Returns\n",
    "            sparse_matrix_coo (scipy.sparse.coo_matrix): Sparse matrix in COO form  \n",
    "    \"\"\"\n",
    "\n",
    "    # Map the movie_ids in the data to the new movie_ids given by the dictionary movie_dict\n",
    "    movie_id_list = list(map(lambda x: movie_dict[x], df['movieId'].tolist()))\n",
    "    # Map the user_id in the dataframe to userid - 1 [to account for zero based indexing]\n",
    "    user_id_list = list(map(lambda x: x - 1, df['userId'].tolist()))\n",
    "    sparse_matrix_coo = sparse.coo_matrix((df['rating'].tolist(),(user_id_list, movie_id_list)),shape=(n_users,n_items))\n",
    "#     logger.debug(\"Shape of created sparse matrix: \" + str(sparse_matrix_coo.shape))\n",
    "#     logger.debug(\"Number of non_zero elements in the sparse matrix: \" + str(sparse_matrix_coo.nnz))\n",
    "#     logger.debug(\"Number of entries in the input dataframe:[should match the number of non zero entries in sparse matrix] \" + str(df.shape[0]))\n",
    "    return sparse_matrix_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# README file for the dataset: http://files.grouplens.org/datasets/movielens/ml-20m-README.html\n",
    "# User-ids are in the range (1, 138493). We just subract 1 from each userId to convert the range to (0,138492)\n",
    "# Total number of movies are 27278 but the the range of movieIds is bigger than (1,27278)\n",
    "# We need to map the movieIds to the range (0,27277)\n",
    "# Only movies with at least one rating or tag are included in the dataset. As we see above, the number of unique movies\n",
    "# for which we have atleast one rating is 26744 \n",
    "ind = 0\n",
    "movie_list = [] # List which is reverse of movie_dict, contains original movieId at index 'new id'\n",
    "movie_dict = {}   # Dictionary from original movieId to new id\n",
    "for movieId in df['movieId'].unique():\n",
    "    movie_list.append(movieId)\n",
    "    movie_dict[movieId] = ind\n",
    "    ind += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sparse matrix for the training, validation and test data\n",
    "sparse_train_coo = create_sparse_coo_matrix(df_train, n_users, n_items, movie_dict)\n",
    "sparse_valid_coo = create_sparse_coo_matrix(df_valid, n_users, n_items, movie_dict)\n",
    "sparse_test_coo = create_sparse_coo_matrix(df_test, n_users, n_items, movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrices to CSR form\n",
    "sparse_train_csr = sparse_train_coo.tocsr()\n",
    "sparse_valid_csr = sparse_valid_coo.tocsr()\n",
    "sparse_test_csr = sparse_test_coo.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2000026,)\n"
     ]
    }
   ],
   "source": [
    "# Ignore\n",
    "valid_data = sparse_valid_csr.data\n",
    "print(type(valid_data))\n",
    "print(valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Average Baseline: Validation MSE: 1.1062901685\n",
      "Global Average Baseline: Test MSE: 1.1057496011\n"
     ]
    }
   ],
   "source": [
    "# Global Average\n",
    "global_avg = sparse_train_csr.sum()/sparse_train_csr.nnz\n",
    "\n",
    "actual_valid = sparse_valid_csr.data\n",
    "pred_valid = np.ones(actual_valid.shape)\n",
    "pred_valid *= global_avg\n",
    "\n",
    "valid_mse = mean_squared_error(pred_valid, actual_valid)\n",
    "\n",
    "actual_test = sparse_test_csr.data\n",
    "pred_test = np.ones(actual_test.shape)\n",
    "pred_test *= global_avg\n",
    "\n",
    "test_mse = mean_squared_error(pred_test, actual_test)\n",
    "\n",
    "print(\"Global Average Baseline: Validation MSE: \" + str(valid_mse))\n",
    "print(\"Global Average Baseline: Test MSE: \" + str(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138493,)\n",
      "[ 3.73021583  3.89130435  4.06711409  3.5         4.28        3.68421053\n",
      "  3.30837004  3.71428571  3.09375     3.88235294]\n",
      "User Average Baseline: Validation MSE: 0.930132260624\n",
      "User Average Baseline: Test MSE: 0.929705570038\n"
     ]
    }
   ],
   "source": [
    "# User Average Baseline\n",
    "data = sparse_train_csr.data\n",
    "indices = sparse_train_csr.indices\n",
    "indptr = sparse_train_csr.indptr\n",
    "\n",
    "user_sum = sparse_train_csr.sum(axis=1)\n",
    "\n",
    "data_useravg = np.empty(shape=(indptr.shape[0] - 1,),dtype=np.float64)\n",
    "for user_num in range(indptr.shape[0] - 1):\n",
    "    data_useravg[user_num] = user_sum[user_num,0] / (indptr[user_num + 1] - indptr[user_num] + 1e-9)\n",
    "    \n",
    "print(data_useravg.shape)\n",
    "print(data_useravg[:10])\n",
    "\n",
    "indptr_valid = sparse_valid_csr.indptr\n",
    "pred_valid_ua = np.empty(shape=actual_valid.shape,dtype=np.float64)\n",
    "\n",
    "for user_num in range(indptr_valid.shape[0] - 1):\n",
    "    pred_valid_ua[indptr_valid[user_num]: indptr_valid[user_num + 1]] = data_useravg[user_num]\n",
    "    \n",
    "indptr_test = sparse_test_csr.indptr\n",
    "pred_test_ua = np.empty(shape=actual_test.shape,dtype=np.float64)\n",
    "\n",
    "for user_num in range(indptr_test.shape[0] - 1):\n",
    "    pred_test_ua[indptr_test[user_num]: indptr_test[user_num + 1]] = data_useravg[user_num]\n",
    "\n",
    "\n",
    "ua_valid_mse = mean_squared_error(pred_valid_ua, actual_valid)\n",
    "ua_test_mse = mean_squared_error(pred_test_ua, actual_test)\n",
    "\n",
    "print(\"User Average Baseline: Validation MSE: \" + str(ua_valid_mse))\n",
    "print(\"User Average Baseline: Test MSE: \" + str(ua_test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Movie Average Baseline\n",
    "\n",
    "\n",
    "# Item item is the same as user user on the transpose of the ratings matrix # Verify this"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
