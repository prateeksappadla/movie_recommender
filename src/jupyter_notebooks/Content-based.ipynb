{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "names_rating = ['user_id', 'movieId', 'rating', 'timestamp']\n",
    "names_tags = ['user_id', 'movieId', 'tag', 'timestamp' ]\n",
    "names_movies = ['movieId', 'title', 'genres']\n",
    "names_links = ['movieId', 'imdb_id', 'tmdb_id']\n",
    "\n",
    "DATA_DIR = 'data/ml-latest-small/'\n",
    "FILE_RATINGS = DATA_DIR + 'ratings.csv'\n",
    "FILE_TAGS = DATA_DIR + 'tags.csv'\n",
    "FILE_MOVIES = DATA_DIR + 'movies.csv'\n",
    "FILE_LINKS = DATA_DIR + 'links.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct movies : 9107\n",
      "Number of distinct Genres 19\n",
      "Item profile generated\n",
      "Number of movies: 9107\n",
      "movie_map size:  9107\n",
      "movies_idx size:  9107\n",
      "movie_ID_list size:  9107\n"
     ]
    }
   ],
   "source": [
    "# reading movies.csv file for genre information and removing movies with empty genres\n",
    "movies_df = pd.read_csv(FILE_MOVIES)\n",
    "no_genres = '(no genres listed)'\n",
    "movies_df = movies_df[movies_df.genres != no_genres]\n",
    "movies_df = movies_df.sort_values(['movieId'], ascending=[1])\n",
    "\n",
    "# Movie Count\n",
    "movies_size = movies_df.movieId.unique().shape[0]\n",
    "print(\"Number of distinct movies : %d\" % movies_size)\n",
    "\n",
    "# Different types of Genres\n",
    "categories = ['Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy',\n",
    "                'Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western','IMAX']\n",
    "\n",
    "genre_size = len(categories)\n",
    "genre_idx = {}\n",
    "ind = 0\n",
    "for cat in categories:\n",
    "    genre_idx[cat] = ind\n",
    "    ind += 1\n",
    "    \n",
    "print(\"Number of distinct Genres %d\" % genre_size)\n",
    "\n",
    "# Extracting different genres into a list from a string and mapping them to an index value\n",
    "def getGenres(line, genre_idx):\n",
    "    genres = line.split('|')\n",
    "    \n",
    "    # checking for no genres\n",
    "    no_genres = 'no genres listed'\n",
    "    if no_genres in genres[0]:\n",
    "        return None\n",
    "    \n",
    "    for idx in range(len(genres)):\n",
    "        val = genre_idx[genres[idx]]\n",
    "        genres[idx] = val\n",
    "    return genres\n",
    "\n",
    "# Storing Movie list and mapping movies to index values\n",
    "# List containing different types of movies \n",
    "movie_ID_list = [] # movie ID\n",
    "movies_idx = {}    # movie ID -> index\n",
    "movie_map = {}     # movie ID -> title\n",
    "\n",
    "# Returns item profile\n",
    "def getitemprofile(df, movie_ID_list, movie_idx, movie_map, movies_size, genre_size, genre_idx):\n",
    "    item_matrix = np.zeros((movies_size, genre_size))\n",
    "    index =0\n",
    "\n",
    "    for indx, row in df.iterrows():\n",
    "        gen = row['genres']\n",
    "        title = row['title']\n",
    "        movieid = row['movieId']\n",
    "        \n",
    "        genres = getGenres(gen, genre_idx)\n",
    "        if genres == None:\n",
    "            continue\n",
    "        for genre in genres:\n",
    "            item_matrix[index, genre] = 1\n",
    "        \n",
    "        # Filling the movie_ID_list, movies_idx, movie_map\n",
    "        if movieid in movies_idx.keys():\n",
    "            print(\"Duplicate Movie: \", title)\n",
    "            continue\n",
    "        movie_ID_list.append(movieid)\n",
    "        movies_idx[movieid] = index\n",
    "        movie_map[movieid] = title\n",
    "        index += 1\n",
    "        # checking for duplicate movie entries\n",
    "    return item_matrix\n",
    "    \n",
    "\n",
    "item_profile = getitemprofile(movies_df, movie_ID_list, movies_idx, movie_map, movies_size, genre_size, genre_idx)\n",
    "print(\"Item profile generated\")\n",
    "print(\"Number of movies: %d\" % len(movies_idx))\n",
    "\n",
    "# Debugging check\n",
    "print(\"movie_map size: \", len(movie_map))\n",
    "print(\"movies_idx size: \", len(movies_idx))\n",
    "print(\"movie_ID_list size: \", len(movie_ID_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 671\n",
      "Number of unique movies: 9107\n",
      "Error not present in database:  Pandas(Index=8762, userId=56, movieId=128620, rating=5.0, timestamp=1467003913)\n",
      "Error not present in database:  Pandas(Index=8781, userId=56, movieId=160590, rating=5.0, timestamp=1467095789)\n",
      "Error not present in database:  Pandas(Index=11812, userId=73, movieId=141866, rating=4.0, timestamp=1469772876)\n",
      "Error not present in database:  Pandas(Index=27677, userId=200, movieId=136592, rating=1.5, timestamp=1438020227)\n",
      "Error not present in database:  Pandas(Index=39521, userId=287, movieId=117192, rating=5.0, timestamp=1473445036)\n",
      "Error not present in database:  Pandas(Index=41926, userId=299, movieId=83829, rating=4.5, timestamp=1344180332)\n",
      "Error not present in database:  Pandas(Index=45613, userId=324, movieId=149532, rating=3.0, timestamp=1451519751)\n",
      "Error not present in database:  Pandas(Index=50521, userId=371, movieId=122888, rating=5.0, timestamp=1473624419)\n",
      "Error not present in database:  Pandas(Index=55788, userId=402, movieId=117192, rating=4.5, timestamp=1462945915)\n",
      "Error not present in database:  Pandas(Index=63684, userId=457, movieId=126106, rating=3.5, timestamp=1471409573)\n",
      "Error not present in database:  Pandas(Index=80785, userId=547, movieId=134025, rating=3.0, timestamp=1432654721)\n",
      "Error not present in database:  Pandas(Index=80816, userId=547, movieId=151307, rating=4.5, timestamp=1472400501)\n",
      "Error not present in database:  Pandas(Index=85189, userId=572, movieId=132952, rating=4.0, timestamp=1436466718)\n",
      "Error not present in database:  Pandas(Index=95198, userId=624, movieId=129250, rating=0.5, timestamp=1447868930)\n",
      "Error not present in database:  Pandas(Index=95257, userId=624, movieId=143410, rating=2.0, timestamp=1474224802)\n",
      "Error not present in database:  Pandas(Index=96989, userId=648, movieId=128616, rating=4.0, timestamp=1426357951)\n",
      "Error not present in database:  Pandas(Index=97385, userId=652, movieId=140753, rating=4.0, timestamp=1439587070)\n",
      "Error not present in database:  Pandas(Index=97390, userId=652, movieId=140763, rating=5.0, timestamp=1439587331)\n"
     ]
    }
   ],
   "source": [
    "# Reading Ratings file\n",
    "ratings_df = pd.read_csv(FILE_RATINGS)\n",
    "n_users = ratings_df['userId'].unique().shape[0]\n",
    "n_items = len(movies_idx) #ratings_df['movieId'].unique().shape[0]\n",
    "print(\"Number of unique users: %d\" % n_users)\n",
    "print(\"Number of unique movies: %d\" % n_items)\n",
    "\n",
    "# Create a dictionary from movieId to index\n",
    "ind = 0\n",
    "movie_dict = movies_idx\n",
    "movie_list = movie_ID_list\n",
    "\n",
    "# Create user-item ratings matrix from the csv file data\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "\n",
    "# df.itertuples() returns a Pandas Frame object\n",
    "for row in ratings_df.itertuples():\n",
    "    if row[2] not in movie_dict.keys():\n",
    "        print(\"Error not present in database: \",row)\n",
    "        continue\n",
    "    ratings[row[1] - 1, movie_dict[row[2]]] = row[3]\n",
    "    \n",
    "\n",
    "# Split data into training and test sets by removing 10 ratings per user from the training set and adding to test set \n",
    "# All selected users had rated at least 20 movies. There are a total of 100004 ratings in this version of the dataset\n",
    "# 10 ratings per user means a test set comprising of 6710 ratings which is around 6.7% of the total data\n",
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)\n",
    "\n",
    "def row_normalize(mat):\n",
    "    eps = 1e-9\n",
    "    mat_mask = (mat != 0).astype(int)\n",
    "    rsum = np.sum(mat, axis=1)\n",
    "    nzcount = np.count_nonzero(mat, axis=1)\n",
    "    avg_rat = rsum/(nzcount + eps)\n",
    "    avg_rat = avg_rat[:, np.newaxis]\n",
    "    mat = mat - avg_rat\n",
    "    mat = mat * mat_mask\n",
    "    return mat, avg_rat\n",
    "\n",
    "train, user_mean = row_normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getuserprof(user_rat, genre_size, item_profile):\n",
    "    nz_count = np.count_nonzero(user_rat)\n",
    "    user_mat = np.zeros((nz_count, genre_size))\n",
    "    rated_movie_idx = np.nonzero(user_rat)[0]\n",
    "    eps = 1e-9\n",
    "    ind = 0\n",
    "    for x in rated_movie_idx:\n",
    "        rating = user_rat[x]\n",
    "        user_mat[ind,:] = item_profile[x,:] * rating\n",
    "        ind += 1\n",
    "    nz = np.count_nonzero(user_mat, axis=0)\n",
    "    user_mat = np.sum(user_mat, axis=0)\n",
    "    user_mat = user_mat/(nz + eps)\n",
    "    return user_mat\n",
    "\n",
    "def getProfiles(train, n_users, genre_size, item_profile):\n",
    "    user_prof = np.zeros((n_users,genre_size))\n",
    "    nrows = train.shape[0]\n",
    "    for i in range(nrows):\n",
    "        val = getuserprof(train[i,:], genre_size, item_profile)\n",
    "        user_prof[i,:] = val\n",
    "    return user_prof\n",
    "\n",
    "user_rat = getProfiles(train, n_users, genre_size, item_profile)\n",
    "\n",
    "t_item_prof = item_profile.transpose()\n",
    "content_mat = np.dot(user_rat, t_item_prof)\n",
    "\n",
    "user_norm = LA.norm(user_rat, axis=1)\n",
    "user_norm = user_norm[:, np.newaxis]\n",
    "\n",
    "t_item_prof_norm = LA.norm(t_item_prof, axis=0)\n",
    "\n",
    "content_mat = content_mat/user_norm\n",
    "content_mat = content_mat/t_item_prof_norm\n",
    "\n",
    "test_mask = (test !=0).astype(int)\n",
    "content_mat = content_mat + user_mean\n",
    "content_mat = content_mat * test_mask\n",
    "mse = mean_squared_error(content_mat, test)\n",
    "\n",
    "# taking into account the unpredicted movies in the test set to normalize the mean squred error value:\n",
    "mse = mse * (9107/10)\n",
    "\n",
    "print(\"Mean Squared Error: \",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content based Recommendation Algorithm:\n",
    "\n",
    "This algorithm takes into account the likes and dislikes of the user and generates a User Profile. For genreating a user profile, we take into account the item profiles( vector discribing an item) and their corresponding user rating.\n",
    "The user profile is the weighted sum of the item profiles with weights being the ratings user rated. Once the user profile is generated, we calculate the similarity of the user profile with all the items in the dataset, which is calculated using cosine similarity between the user profile and item profile. Advantages of Content Based approach is that data of other users is not required and the recommender engine can recommend new items which are not rated currently, but the recommender algorithm doesn't recommend the items outside the category of items the user has rated.\n",
    "\n",
    "For the current movie recommendation algorithm we take into account the genre of the movie as the description vector for item profile. However, it is not the optimal criteria to use for movie recommendation, as the user is generally not loyal to a praticular genre or actor or director. We need better discriptors of a movie for better prediction."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
